<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/interfaces_blog/_next/static/css/714c847259b3d496.css" data-precedence="next"/><link rel="stylesheet" href="/interfaces_blog/_next/static/css/c9d082c180907b01.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/interfaces_blog/_next/static/chunks/webpack-2176e5bdd3b14dfa.js"/><script src="/interfaces_blog/_next/static/chunks/4bd1b696-6e92223d928976cc.js" async=""></script><script src="/interfaces_blog/_next/static/chunks/684-21fd19373ae80d0f.js" async=""></script><script src="/interfaces_blog/_next/static/chunks/main-app-fbca3d3476c8da1d.js" async=""></script><script src="/interfaces_blog/_next/static/chunks/63-cc26e9f689b889d4.js" async=""></script><script src="/interfaces_blog/_next/static/chunks/874-6cb6c5124d827682.js" async=""></script><script src="/interfaces_blog/_next/static/chunks/app/page-72a6016363f3622d.js" async=""></script><script src="/interfaces_blog/_next/static/chunks/14-1f9ac665d167bcf6.js" async=""></script><script src="/interfaces_blog/_next/static/chunks/app/(pages)/blog/%5BpostId%5D/page-8a861a2caa4339e5.js" async=""></script><title>Interface Blog</title><meta name="description" content="A blog by Gabriele Costanza about technology, ai, programming, data engineering and cloud technologies."/><meta name="application-name" content="interfaces_blog"/><meta name="keywords" content="interfaces_blog"/><link rel="canonical" href="https://gabrielecodes.github.io/interfaces_blog/"/><meta property="og:title" content="interfaces_blog"/><meta property="og:description" content="A blog by Gabriele Costanza about technology, ai, programming, data engineering and cloud technologies."/><meta property="og:url" content="https://gabrielecodes.github.io/interfaces_blog/"/><meta property="og:site_name" content="interfaces_blog"/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="interfaces_blog"/><meta name="twitter:description" content="A blog by Gabriele Costanza about technology, ai, programming, data engineering and cloud technologies."/><link rel="icon" href="/interfaces_blog/favicon.ico" type="image/x-icon" sizes="16x16"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/interfaces_blog/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="font-helvetica antialiased selection-[#DAA520]"><div class="lg:w-[45%] w-[90%] mx-auto"><header class="w-full h-20 mx-auto font-serif font-normal sticky top-0 bg-background border-b border-neutral-700 z-10"><nav class="mx-auto pt-10 flex justify-between"><a href="/interfaces_blog"><h2 class="hover:text-neutral-50"> ℑnterfaces Blog</h2></a><ul class="flex gap-10"><li class="md:w-fit md:visible w-0 invisible"><a href="/interfaces_blog"><h2 class="hover:text-neutral-50">Home</h2></a></li><li><a href="/interfaces_blog/about"><h2 class="hover:text-neutral-50">About</h2></a></li></ul></nav></header><section class="mt-20"><article><div class="w-full h-60 mb-10 rounded-md relative"><img alt="alt" loading="lazy" decoding="async" data-nimg="fill" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;object-fit:cover;color:transparent;border-radius:6px" src="/interfaces_blog/gradient3.jpg"/><h1 class="px-2 m-2 absolute bottom-0 bg-background rounded-md">Atomics, Locks and Micro Benchmarks</h1></div><p>I&#x27;m working on a rust crate that implements a FIFO queue using atomics so I&#x27;ve begun a series of experiments to understand their performance tradeoffs. I&#x27;m also adding some comments here and there that might be useful to those venturing in this field for the first time.<br/><br/>In simple terms, atomic types and operations are building blocks for concurrent programming, allowing for indivisible operations on shared memory without the costly synchronization of traditional locks. It&#x27;s an interesting subject to me and it gives me a chance to take a pause from traditional locks. If you&#x27;re interested in the subject I recommend the CPPCon YT videos, they are a gold mine when it comes to high-performance computing and<!-- --> <a href="https://en.wikipedia.org/wiki/Lock_(computer_science)" class="underline" rel="nofollow" target="_blank"><em>lock-free</em></a> <!-- -->programming.<br/><br/>With performance sensitive code, even an innocent-looking operation may imply a significant penalty in performance, and I&#x27;d like to avoid that. To understand better the possible performance issues I want to look at the disassembled code as well. Perhaps that will help in explaining some of the results.<br/><br/></p><h2 class="mb-4">Setup</h2><p>As a starting point, I&#x27;ve defined a simple <mark>nop</mark> function – an operation that does absolutely nothing. This serves to establish a baseline performance measurement. Then, I&#x27;m progressively testing more complex functions adding operations. The goal is to observe some performance regression and perhaps understand what&#x27;s behind it. A few notes:</p><ul class="list-disc my-2 text-textcolor"><li class="ml-8">I&#x27;m using an old i7 Mac,</li><li class="ml-8">I&#x27;m using the standard memory allocator (no jemalloc/mimalloc),</li><li class="ml-8">I&#x27;m compling with <mark>opt-level=3</mark>.</li><li class="ml-8">I&#x27;m not using <mark>perf</mark> or similar for this one, just measuring time. It&#x27;s not the perfect way to proceed but it should be enough to give me a sense of what I&#x27;m working with. I measure average and variance. I&#x27;m aiming at having better benchmarks for part 2.</li></ul><p>Let&#x27;s look at the <mark>nop</mark> function and its disassembled code. They are almost 1-to-1 comparable:</p><div class="my-4 md:flex overflow-scroll rounded-md bg-code"><div class="p-4"><div class="mb-3 border-b border-neutral-500">rust</div><pre class="w-full flex rounded-md"><code class="pl-2 rust">fn nop() {
    black_box(());
}</code></pre></div><div class="p-4"><div class="mb-3 border-b border-neutral-500">asm</div><pre class="w-full flex rounded-md"><code class="pl-2 asm">push    rax
call    qword ptr [rip + core::hint::black_box::h86d1574ace50d079@GOTPCREL]
pop     rax
ret</code></pre></div></div><p>No surprises here, it is indeed simple. Overall the compiler is aggressive but quite smart. Without the<!-- --> <mark>black_box</mark> the whole function would be optimized away, so we need to suggest the compiler to not remove it. Also in the function <mark>try_push</mark> (down below), bounds check are eliminated depending if the writes are in the loop or outside. I guess it&#x27;s not all that surprising but it&#x27;s cool to see.<br/> <br/> First, I&#x27;ll measure the time of the following iterated call to <mark>nop</mark>, just to set a baseline performance:</p><div class="my-4 rounded-md bg-code"><div class="p-4"><pre class="w-full flex rounded-md"><code class="pl-2 rust">const ITERS: u64 = 10_000_000;

#[no_mangle]
fn nop() {
    for _ in 1..ITERS {
        black_box(());
    }
}
</code></pre></div></div><p>After that, I want to make some tests with an increasing amount of operations, using functions that I would need to use for the queue:</p><div class="my-4 rounded-md bg-code"><div class="p-4"><pre class="w-full flex rounded-md"><code class="pl-2 rust">##[inline(never)]
fn atomic_load(val: &amp;AtomicU64) {
    for _ in 1..ITERS {
        val.load(Ordering::Acquire);
    }
}

#[inline(never)]
fn atomic_load_store(val: &amp;AtomicU64) {
    for i in 1..ITERS {
        black_box(val.store(i, Ordering::Release));
        black_box(val.load(Ordering::Acquire));
    }
}

// here &quot;slice&quot; stores &quot;ITERS&quot; number of elements
#[inline(never)]
fn try_push(val: &amp;AtomicU64, slice: &amp;mut Box&lt;[MaybeUninit&lt;u64&gt;]&gt;) {
    for i in 1..slice.len() {
        black_box(val.load(Ordering::Relaxed));
        black_box(val.load(Ordering::Acquire));
        slice[i].write(i as u64);
    }
}</code></pre></div></div><p>In case you&#x27;re curious, the disassembled code for the load and store are here below. It doesn&#x27;t look intimidating so we shouldn&#x27;t have a large performance degradation:</p><div class="my-4 md:flex overflow-scroll rounded-md bg-code"><div class="p-4"><div class="mb-3 border-b border-neutral-500">rust</div><pre class="w-full flex rounded-md"><code class="pl-2 rust">val.load(Ordering::Acquire);</code></pre></div><div class="p-4"><div class="mb-3 border-b border-neutral-500">asm</div><pre class="w-full flex rounded-md"><code class="pl-2 asm">mov     rax, qword ptr [rdi]
mov     qword ptr [rsp - 8], rax
lea     rax, [rsp - 8]</code></pre></div></div><div class="my-4 md:flex overflow-scroll rounded-md bg-code"><div class="p-4"><div class="mb-3 border-b border-neutral-500">rust</div><pre class="w-full flex rounded-md"><code class="pl-2 rust">val.store(1, Ordering::Release)</code></pre></div><div class="p-4"><div class="mb-3 border-b border-neutral-500">asm</div><pre class="w-full flex rounded-md"><code class="pl-2 asm">mov     qword ptr [rdi], 1</code></pre></div></div><h2 class="my-4">First Results</h2><p>Time to test things out. Here are the results averaged over 25 tests:</p><table class="-ml-4 my-4 border-separate border-spacing-x-4 border-spacing-y-2"><thead><tr class="text-left space-x-4"><th class="border-b">Test</th><th class="border-b">Ratio</th><th class="border-b">Variance</th><th class="border-b">Visual</th></tr></thead><tbody><tr><td>nop</td><td>1</td><td>0.18</td><td class="w-full"><div class="w-[20px] bg-emerald-400 text-emerald-400">|</div></td></tr><tr><td>atomic_load</td><td>1.47</td><td>0.25</td><td class="w-full"><div class="w-[29.4px] bg-emerald-400 text-emerald-400">|</div></td></tr><tr><td>atomic_load_store</td><td>3.34</td><td>0.4</td><td class="w-full"><div class="w-[66.8px] bg-emerald-400 text-emerald-400">|</div></td></tr><tr><td>try_push</td><td>5.17</td><td>24.45</td><td class="w-full"><div class="w-[103.4px] bg-emerald-400 text-emerald-400">|</div></td></tr></tbody></table><p>I can attempt a to draw a couple of conclusions:</p><ul class="list-disc my-2 text-textcolor"><li class="ml-8">Atomic loads and stores are fast. Only slightly slower than <mark>nop</mark>.</li><li class="ml-8">It&#x27;s not surprising that <mark>atomic_load_store</mark> takes about twice as long as<!-- --> <mark>atomic_load</mark> given that we&#x27;re doing nearly twice as many operations.</li><li class="ml-8">The much slower <mark>try_push</mark> is writing to memory, I&#x27;m guessing that&#x27;s what&#x27;s behind the performance hit. The variance is also much higher.</li></ul><h2 class="my-4">Atomic Operations</h2><p>Next, I want to test atomic operations, in particular, <mark>fetch_add</mark> and <mark>compare_exchange</mark>. These are often used in lock-free programming and I may need them in the queue logic. Here below are the test functions.</p><div class="my-4 md:flex overflow-scroll rounded-md bg-code"><div class="p-4"><pre class="w-full flex rounded-md"><code class="pl-2 rust">#[inline(never)]
fn fetch_add(val: &amp;AtomicU64) {
    for i in 1..ITERS {
        val.fetch_add(i, Ordering::Release);
    }
}

#[inline(never)]
fn cas(val: &amp;AtomicU64) {
    for i in 1..ITERS {
        let current = val.load(Ordering::Relaxed);
        let _ = val.compare_exchange(current, i, Ordering::Release, Ordering::Relaxed);
    }
}</code></pre></div></div><p>The results are below (where I repeat the previous ones for clarity):</p><table class="-ml-4 my-4 border-separate border-spacing-x-4 border-spacing-y-2"><thead><tr class="text-left space-x-4"><th class="border-b">Test</th><th class="border-b">Ratio</th><th class="border-b">Variance</th><th class="border-b">Visual</th></tr></thead><tbody><tr><td>nop</td><td>1</td><td>0.18</td><td class="w-full"><div class="w-[4px] bg-emerald-400 text-emerald-400">|</div></td></tr><tr><td>atomic_load</td><td>1.47</td><td>0.25</td><td class="w-full"><div class="w-[5.88px] bg-emerald-400 text-emerald-400">|</div></td></tr><tr><td>atomic_load_store</td><td>3.34</td><td>0.4</td><td class="w-full"><div class="w-[13.36px] bg-emerald-400 text-emerald-400">|</div></td></tr><tr><td>try_push</td><td>5.17</td><td>24.45</td><td class="w-full"><div class="w-[20.68px] bg-emerald-400 text-emerald-400">|</div></td></tr><tr><td class="text-[#33ffbd]">fetch_add</td><td>16.05</td><td>0.68</td><td class="w-full"><div class="w-[64.2px] bg-emerald-400 text-emerald-400">|</div></td></tr><tr><td class="text-[#33ffbd]">cas</td><td>25.34</td><td>3.27</td><td class="w-full"><div class="w-[101.36px] bg-emerald-400 text-emerald-400">|</div></td></tr></tbody></table><p>Now we&#x27;re starting to see a real performance drop, although notice how the variance of the new tests is back down, close to the &quot;nop&quot; variance. I&#x27;m going straight to the assembly for the<!-- --> <mark>fetch_add</mark>:</p><div class="my-4 md:flex overflow-scroll rounded-md bg-code"><div class="p-4"><pre class="w-full flex rounded-md"><code class="pl-2 asm">// fetch_add function
fetch_add:
        mov     eax, 1
.LBB0_1:
        lock            add     qword ptr [rdi], rax
        lea     rcx, [rax + 1]
        lock            add     qword ptr [rdi], rcx
        lea     rcx, [rax + 2]
        lock            add     qword ptr [rdi], rcx
        lea     rcx, [rax + 3]
        lock            add     qword ptr [rdi], rcx
        lea     rcx, [rax + 4]
        lock            add     qword ptr [rdi], rcx
        lea     rcx, [rax + 5]
        lock            add     qword ptr [rdi], rcx
        lea     rcx, [rax + 6]
        lock            add     qword ptr [rdi], rcx
        lea     rcx, [rax + 7]
        lock            add     qword ptr [rdi], rcx
        lea     rcx, [rax + 8]
        lock            add     qword ptr [rdi], rcx
        add     rax, 9
        cmp     rax, 10000000
        jne     .LBB0_1
        ret</code></pre></div></div><p>There is indeed some form of locking involved with the atomic <mark>fetch_add</mark>. I&#x27;m guessing this is the reason behind the results, there isn&#x27;t really much else in the function. I don&#x27;t see it as a discouraging fact though, just because there is <em>some form</em> of locking it doesn&#x27;t mean that we&#x27;re back to square one. This form of hardware-level locking is <em>not like</em> the mutexes we&#x27;re used to, There are two important ideas to mention:</p><ul class="my-2 text-textcolor list-disc"><li class="ml-8">we are avoiding explicit locking acquisition and release in the code. I bet this saves us time.</li><li class="ml-8">Progress is guaranteed in a well-designed lock-free multithreaded algorithm.</li></ul><p>As I understand it, in lock-free multithreaded algorithms, one thread is guaranteed to make progress, so overall, our system doesn&#x27;t reach a deadlocked state, and this is a significant victory. Of course we can still<!-- --> <a href="https://lwn.net/Articles/847973/" class="underline" rel="nofollow" target="_blank">make mistakes</a> <!-- -->in our program logic, leading to one thread to read the wrong/outaded value, so atomic operations alone aren&#x27;t sufficient for logical soundness.<br/><br/>In other words, since there is no mutual exclusion, shared memory is not &quot;locked&quot; so there is no &quot;holding and waiting&quot;. We need to take that into account in the lock-free logic. A second thread can modify the shared memory while the first is still needing it, and due to it&#x27;s logic, it&#x27;s expecting to find the original value. We need to handle this problem, and that&#x27;s where <mark>compare_exchange</mark> <!-- -->comes in handy. It compares the current shared value to the expected one, on success, the current variable is updated with the value. Together with a classic <mark>if</mark> statement it becomes a powerful tool.<br/><br/>Also <mark>compare_exchange</mark> involves locking, although here we&#x27;re packing more instructions in a single function:</p><div class="my-4 md:flex overflow-scroll rounded-md bg-code"><div class="p-4"><pre class="w-full flex rounded-md"><code class="pl-2 asm">// compare_exchange
cas:
        mov     edx, 1
        lea     rcx, [rsp - 16]
.LBB0_1:
        mov     rax, qword ptr [rdi]
        xor     esi, esi
        lock            cmpxchg qword ptr [rdi], rdx
        lea     r8, [rdx + 1]
        setne   sil
        mov     qword ptr [rsp - 16], rsi
        mov     qword ptr [rsp - 8], rax
        mov     rdx, r8
        cmp     r8, 10000000
        jne     .LBB0_1
        ret</code></pre></div></div><p><mark>cmpxchg</mark> is the actual CAS operation but the other instructions are a necessary part of the whole compare exchange logic as well. I won&#x27;t go into details here, there are good documents online that explain the logic. From our perspective, it seems reasonable that the CAS operation involves a performance degradation but in exchange we get the possibility to write logically sound, multithreaded and lock-free algorithms.<br/><br/></p><h2 class="mb-4"> Conclusion </h2><p>Lock-free algorithms are very interesting. I&#x27;m promising myself to write a part 2 where I show the logic of the FIFO queue I&#x27;m working on. For now, I hope somebody finds this useful or interesting.</p></article><!--$--><!--/$--><!--$--><!--/$--></section><footer class="h-12 mt-10 border-t border-neutral-700 flex items-center"><p class="text-sm text-[#616161]">Gabriele Costanza© 2025</p></footer></div><script src="/interfaces_blog/_next/static/chunks/webpack-2176e5bdd3b14dfa.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[6874,[\"63\",\"static/chunks/63-cc26e9f689b889d4.js\",\"874\",\"static/chunks/874-6cb6c5124d827682.js\",\"974\",\"static/chunks/app/page-72a6016363f3622d.js\"],\"\"]\n3:I[7555,[],\"\"]\n4:I[1295,[],\"\"]\n6:I[9665,[],\"MetadataBoundary\"]\n8:I[9665,[],\"OutletBoundary\"]\nb:I[4911,[],\"AsyncMetadataOutlet\"]\nd:I[9665,[],\"ViewportBoundary\"]\nf:I[6614,[],\"\"]\n:HL[\"/interfaces_blog/_next/static/css/714c847259b3d496.css\",\"style\"]\n:HL[\"/interfaces_blog/_next/static/css/c9d082c180907b01.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"2hQdnlW6NSib70_cJs3ss\",\"p\":\"/interfaces_blog\",\"c\":[\"\",\"blog\",\"atomic-ops\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"(pages)\",{\"children\":[\"blog\",{\"children\":[[\"postId\",\"atomic-ops\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/interfaces_blog/_next/static/css/714c847259b3d496.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"font-helvetica antialiased selection-[#DAA520]\",\"children\":[\"$\",\"div\",null,{\"className\":\"lg:w-[45%] w-[90%] mx-auto\",\"children\":[[\"$\",\"header\",null,{\"className\":\"w-full h-20 mx-auto font-serif font-normal sticky top-0 bg-background border-b border-neutral-700 z-10\",\"children\":[\"$\",\"nav\",null,{\"className\":\"mx-auto pt-10 flex justify-between\",\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/\",\"children\":[\"$\",\"h2\",null,{\"className\":\"hover:text-neutral-50\",\"children\":\" ℑnterfaces Blog\"}]}],[\"$\",\"ul\",null,{\"className\":\"flex gap-10\",\"children\":[[\"$\",\"li\",null,{\"className\":\"md:w-fit md:visible w-0 invisible\",\"children\":[\"$\",\"$L2\",null,{\"href\":\"/\",\"children\":[\"$\",\"h2\",null,{\"className\":\"hover:text-neutral-50\",\"children\":\"Home\"}]}]}],[\"$\",\"li\",null,{\"children\":[\"$\",\"$L2\",null,{\"href\":\"/about\",\"children\":[\"$\",\"h2\",null,{\"className\":\"hover:text-neutral-50\",\"children\":\"About\"}]}]}]]}]]}]}],[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"className\":\"h-12 mt-10 border-t border-neutral-700 flex items-center\",\"children\":[\"$\",\"p\",null,{\"className\":\"text-sm text-[#616161]\",\"children\":\"Gabriele Costanza© 2025\"}]}]]}]}]}]]}],{\"children\":[\"(pages)\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"section\",null,{\"className\":\"mt-20\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:props:children:1:props:notFound:0:1:props:style\",\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:props:children:1:props:notFound:0:1:props:children:props:children:1:props:style\",\"children\":404}],[\"$\",\"div\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:props:children:1:props:notFound:0:1:props:children:props:children:2:props:style\",\"children\":[\"$\",\"h2\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:props:children:1:props:notFound:0:1:props:children:props:children:2:props:children:props:style\",\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"postId\",\"atomic-ops\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",[\"$\",\"$L6\",null,{\"children\":\"$L7\"}],[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/interfaces_blog/_next/static/css/c9d082c180907b01.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L8\",null,{\"children\":[\"$L9\",\"$La\",[\"$\",\"$Lb\",null,{\"promise\":\"$@c\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"CxQgWZOZq32Is7tu5AD7a\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],null]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"10:\"$Sreact.suspense\"\n11:I[4911,[],\"AsyncMetadata\"]\n7:[\"$\",\"$10\",null,{\"fallback\":null,\"children\":[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]}]\n"])</script><script>self.__next_f.push([1,"13:I[255,[\"63\",\"static/chunks/63-cc26e9f689b889d4.js\",\"14\",\"static/chunks/14-1f9ac665d167bcf6.js\",\"697\",\"static/chunks/app/(pages)/blog/%5BpostId%5D/page-8a861a2caa4339e5.js\"],\"PreloadChunks\"]\na:null\n5:[[\"$\",\"$L13\",null,{\"moduleIds\":\"$undefined\"}],\"$L14\"]\n"])</script><script>self.__next_f.push([1,"15:I[3063,[\"63\",\"static/chunks/63-cc26e9f689b889d4.js\",\"14\",\"static/chunks/14-1f9ac665d167bcf6.js\",\"697\",\"static/chunks/app/(pages)/blog/%5BpostId%5D/page-8a861a2caa4339e5.js\"],\"Image\"]\n16:I[2375,[\"63\",\"static/chunks/63-cc26e9f689b889d4.js\",\"14\",\"static/chunks/14-1f9ac665d167bcf6.js\",\"697\",\"static/chunks/app/(pages)/blog/%5BpostId%5D/page-8a861a2caa4339e5.js\"],\"default\"]\n"])</script><script>self.__next_f.push([1,"14:[\"$\",\"article\",null,{\"children\":[[\"$\",\"div\",null,{\"className\":\"w-full h-60 mb-10 rounded-md relative\",\"children\":[[\"$\",\"$L15\",null,{\"src\":\"/interfaces_blog/gradient3.jpg\",\"alt\":\"alt\",\"style\":{\"borderRadius\":\"6px\",\"objectFit\":\"cover\"},\"fill\":true}],[\"$\",\"h1\",null,{\"className\":\"px-2 m-2 absolute bottom-0 bg-background rounded-md\",\"children\":\"Atomics, Locks and Micro Benchmarks\"}]]}],[\"$\",\"p\",null,{\"children\":[\"I'm working on a rust crate that implements a FIFO queue using atomics so I've begun a series of experiments to understand their performance tradeoffs. I'm also adding some comments here and there that might be useful to those venturing in this field for the first time.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"In simple terms, atomic types and operations are building blocks for concurrent programming, allowing for indivisible operations on shared memory without the costly synchronization of traditional locks. It's an interesting subject to me and it gives me a chance to take a pause from traditional locks. If you're interested in the subject I recommend the CPPCon YT videos, they are a gold mine when it comes to high-performance computing and\",\" \",[\"$\",\"a\",null,{\"href\":\"https://en.wikipedia.org/wiki/Lock_(computer_science)\",\"className\":\"underline\",\"rel\":\"nofollow\",\"target\":\"_blank\",\"children\":[\"$\",\"em\",null,{\"children\":\"lock-free\"}]}],\" \",\"programming.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"With performance sensitive code, even an innocent-looking operation may imply a significant penalty in performance, and I'd like to avoid that. To understand better the possible performance issues I want to look at the disassembled code as well. Perhaps that will help in explaining some of the results.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}]]}],[\"$\",\"h2\",null,{\"className\":\"mb-4\",\"children\":\"Setup\"}],[\"$\",\"p\",null,{\"children\":[\"As a starting point, I've defined a simple \",[\"$\",\"mark\",null,{\"children\":\"nop\"}],\" function – an operation that does absolutely nothing. This serves to establish a baseline performance measurement. Then, I'm progressively testing more complex functions adding operations. The goal is to observe some performance regression and perhaps understand what's behind it. A few notes:\"]}],[\"$\",\"ul\",null,{\"className\":\"list-disc my-2 text-textcolor\",\"children\":[[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":\"I'm using an old i7 Mac,\"}],[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":\"I'm using the standard memory allocator (no jemalloc/mimalloc),\"}],[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":[\"I'm compling with \",[\"$\",\"mark\",null,{\"children\":\"opt-level=3\"}],\".\"]}],[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":[\"I'm not using \",[\"$\",\"mark\",null,{\"children\":\"perf\"}],\" or similar for this one, just measuring time. It's not the perfect way to proceed but it should be enough to give me a sense of what I'm working with. I measure average and variance. I'm aiming at having better benchmarks for part 2.\"]}]]}],[\"$\",\"p\",null,{\"children\":[\"Let's look at the \",[\"$\",\"mark\",null,{\"children\":\"nop\"}],\" function and its disassembled code. They are almost 1-to-1 comparable:\"]}],[\"$\",\"div\",null,{\"className\":\"my-4 md:flex overflow-scroll rounded-md bg-code\",\"children\":[[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 border-b border-neutral-500\",\"children\":\"rust\"}],[\"$\",\"$L16\",null,{\"lineNumbers\":false,\"lang\":\"rust\",\"code\":\"fn nop() {\\n    black_box(());\\n}\"}]]}],[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 border-b border-neutral-500\",\"children\":\"asm\"}],[\"$\",\"$L16\",null,{\"lineNumbers\":false,\"lang\":\"asm\",\"code\":\"push    rax\\ncall    qword ptr [rip + core::hint::black_box::h86d1574ace50d079@GOTPCREL]\\npop     rax\\nret\"}]]}]]}],[\"$\",\"p\",null,{\"children\":[\"No surprises here, it is indeed simple. Overall the compiler is aggressive but quite smart. Without the\",\" \",[\"$\",\"mark\",null,{\"children\":\"black_box\"}],\" the whole function would be optimized away, so we need to suggest the compiler to not remove it. Also in the function \",[\"$\",\"mark\",null,{\"children\":\"try_push\"}],\" (down below), bounds check are eliminated depending if the writes are in the loop or outside. I guess it's not all that surprising but it's cool to see.\",[\"$\",\"br\",null,{}],\" \",[\"$\",\"br\",null,{}],\" First, I'll measure the time of the following iterated call to \",[\"$\",\"mark\",null,{\"children\":\"nop\"}],\", just to set a baseline performance:\"]}],[\"$\",\"div\",null,{\"className\":\"my-4 rounded-md bg-code\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[\"$\",\"$L16\",null,{\"lineNumbers\":false,\"lang\":\"rust\",\"code\":\"const ITERS: u64 = 10_000_000;\\n\\n#[no_mangle]\\nfn nop() {\\n    for _ in 1..ITERS {\\n        black_box(());\\n    }\\n}\\n\"}]}]}],[\"$\",\"p\",null,{\"children\":\"After that, I want to make some tests with an increasing amount of operations, using functions that I would need to use for the queue:\"}],[\"$\",\"div\",null,{\"className\":\"my-4 rounded-md bg-code\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[\"$\",\"$L16\",null,{\"lineNumbers\":false,\"lang\":\"rust\",\"code\":\"##[inline(never)]\\nfn atomic_load(val: \u0026AtomicU64) {\\n    for _ in 1..ITERS {\\n        val.load(Ordering::Acquire);\\n    }\\n}\\n\\n#[inline(never)]\\nfn atomic_load_store(val: \u0026AtomicU64) {\\n    for i in 1..ITERS {\\n        black_box(val.store(i, Ordering::Release));\\n        black_box(val.load(Ordering::Acquire));\\n    }\\n}\\n\\n// here \\\"slice\\\" stores \\\"ITERS\\\" number of elements\\n#[inline(never)]\\nfn try_push(val: \u0026AtomicU64, slice: \u0026mut Box\u003c[MaybeUninit\u003cu64\u003e]\u003e) {\\n    for i in 1..slice.len() {\\n        black_box(val.load(Ordering::Relaxed));\\n        black_box(val.load(Ordering::Acquire));\\n        slice[i].write(i as u64);\\n    }\\n}\"}]}]}],[\"$\",\"p\",null,{\"children\":\"In case you're curious, the disassembled code for the load and store are here below. It doesn't look intimidating so we shouldn't have a large performance degradation:\"}],[\"$\",\"div\",null,{\"className\":\"my-4 md:flex overflow-scroll rounded-md bg-code\",\"children\":[[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 border-b border-neutral-500\",\"children\":\"rust\"}],[\"$\",\"$L16\",null,{\"lineNumbers\":false,\"lang\":\"rust\",\"code\":\"val.load(Ordering::Acquire);\"}]]}],[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 border-b border-neutral-500\",\"children\":\"asm\"}],[\"$\",\"$L16\",null,{\"lineNumbers\":false,\"lang\":\"asm\",\"code\":\"mov     rax, qword ptr [rdi]\\nmov     qword ptr [rsp - 8], rax\\nlea     rax, [rsp - 8]\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"my-4 md:flex overflow-scroll rounded-md bg-code\",\"children\":[[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 border-b border-neutral-500\",\"children\":\"rust\"}],[\"$\",\"$L16\",null,{\"lineNumbers\":false,\"lang\":\"rust\",\"code\":\"val.store(1, Ordering::Release)\"}]]}],[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"mb-3 border-b border-neutral-500\",\"children\":\"asm\"}],[\"$\",\"$L16\",null,{\"lineNumbers\":false,\"lang\":\"asm\",\"code\":\"mov     qword ptr [rdi], 1\"}]]}]]}],[\"$\",\"h2\",null,{\"className\":\"my-4\",\"children\":\"First Results\"}],[\"$\",\"p\",null,{\"children\":\"Time to test things out. Here are the results averaged over 25 tests:\"}],[\"$\",\"table\",null,{\"className\":\"-ml-4 my-4 border-separate border-spacing-x-4 border-spacing-y-2\",\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"className\":\"text-left space-x-4\",\"children\":[[\"$\",\"th\",null,{\"className\":\"border-b\",\"children\":\"Test\"}],[\"$\",\"th\",null,{\"className\":\"border-b\",\"children\":\"Ratio\"}],[\"$\",\"th\",null,{\"className\":\"border-b\",\"children\":\"Variance\"}],[\"$\",\"th\",null,{\"className\":\"border-b\",\"children\":\"Visual\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"nop\"}],[\"$\",\"td\",null,{\"children\":\"1\"}],[\"$\",\"td\",null,{\"children\":\"0.18\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[20px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"atomic_load\"}],[\"$\",\"td\",null,{\"children\":\"1.47\"}],[\"$\",\"td\",null,{\"children\":\"0.25\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[29.4px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"atomic_load_store\"}],[\"$\",\"td\",null,{\"children\":\"3.34\"}],[\"$\",\"td\",null,{\"children\":\"0.4\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[66.8px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"try_push\"}],[\"$\",\"td\",null,{\"children\":\"5.17\"}],[\"$\",\"td\",null,{\"children\":\"24.45\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[103.4px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}]]}]]}],[\"$\",\"p\",null,{\"children\":\"I can attempt a to draw a couple of conclusions:\"}],[\"$\",\"ul\",null,{\"className\":\"list-disc my-2 text-textcolor\",\"children\":[[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":[\"Atomic loads and stores are fast. Only slightly slower than \",[\"$\",\"mark\",null,{\"children\":\"nop\"}],\".\"]}],[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":[\"It's not surprising that \",[\"$\",\"mark\",null,{\"children\":\"atomic_load_store\"}],\" takes about twice as long as\",\" \",[\"$\",\"mark\",null,{\"children\":\"atomic_load\"}],\" given that we're doing nearly twice as many operations.\"]}],[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":[\"The much slower \",[\"$\",\"mark\",null,{\"children\":\"try_push\"}],\" is writing to memory, I'm guessing that's what's behind the performance hit. The variance is also much higher.\"]}]]}],[\"$\",\"h2\",null,{\"className\":\"my-4\",\"children\":\"Atomic Operations\"}],[\"$\",\"p\",null,{\"children\":[\"Next, I want to test atomic operations, in particular, \",[\"$\",\"mark\",null,{\"children\":\"fetch_add\"}],\" and \",[\"$\",\"mark\",null,{\"children\":\"compare_exchange\"}],\". These are often used in lock-free programming and I may need them in the queue logic. Here below are the test functions.\"]}],[\"$\",\"div\",null,{\"className\":\"my-4 md:flex overflow-scroll rounded-md bg-code\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[\"$\",\"$L16\",null,{\"lang\":\"rust\",\"lineNumbers\":false,\"code\":\"#[inline(never)]\\nfn fetch_add(val: \u0026AtomicU64) {\\n    for i in 1..ITERS {\\n        val.fetch_add(i, Ordering::Release);\\n    }\\n}\\n\\n#[inline(never)]\\nfn cas(val: \u0026AtomicU64) {\\n    for i in 1..ITERS {\\n        let current = val.load(Ordering::Relaxed);\\n        let _ = val.compare_exchange(current, i, Ordering::Release, Ordering::Relaxed);\\n    }\\n}\"}]}]}],[\"$\",\"p\",null,{\"children\":\"The results are below (where I repeat the previous ones for clarity):\"}],[\"$\",\"table\",null,{\"className\":\"-ml-4 my-4 border-separate border-spacing-x-4 border-spacing-y-2\",\"children\":[[\"$\",\"thead\",null,{\"children\":[\"$\",\"tr\",null,{\"className\":\"text-left space-x-4\",\"children\":[[\"$\",\"th\",null,{\"className\":\"border-b\",\"children\":\"Test\"}],[\"$\",\"th\",null,{\"className\":\"border-b\",\"children\":\"Ratio\"}],[\"$\",\"th\",null,{\"className\":\"border-b\",\"children\":\"Variance\"}],[\"$\",\"th\",null,{\"className\":\"border-b\",\"children\":\"Visual\"}]]}]}],[\"$\",\"tbody\",null,{\"children\":[[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"nop\"}],[\"$\",\"td\",null,{\"children\":\"1\"}],[\"$\",\"td\",null,{\"children\":\"0.18\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[4px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"atomic_load\"}],[\"$\",\"td\",null,{\"children\":\"1.47\"}],[\"$\",\"td\",null,{\"children\":\"0.25\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[5.88px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"atomic_load_store\"}],[\"$\",\"td\",null,{\"children\":\"3.34\"}],[\"$\",\"td\",null,{\"children\":\"0.4\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[13.36px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"children\":\"try_push\"}],[\"$\",\"td\",null,{\"children\":\"5.17\"}],[\"$\",\"td\",null,{\"children\":\"24.45\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[20.68px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"text-[#33ffbd]\",\"children\":\"fetch_add\"}],[\"$\",\"td\",null,{\"children\":\"16.05\"}],[\"$\",\"td\",null,{\"children\":\"0.68\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[64.2px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}],[\"$\",\"tr\",null,{\"children\":[[\"$\",\"td\",null,{\"className\":\"text-[#33ffbd]\",\"children\":\"cas\"}],[\"$\",\"td\",null,{\"children\":\"25.34\"}],[\"$\",\"td\",null,{\"children\":\"3.27\"}],[\"$\",\"td\",null,{\"className\":\"w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-[101.36px] bg-emerald-400 text-emerald-400\",\"children\":\"|\"}]}]]}]]}]]}],[\"$\",\"p\",null,{\"children\":[\"Now we're starting to see a real performance drop, although notice how the variance of the new tests is back down, close to the \\\"nop\\\" variance. I'm going straight to the assembly for the\",\" \",[\"$\",\"mark\",null,{\"children\":\"fetch_add\"}],\":\"]}],[\"$\",\"div\",null,{\"className\":\"my-4 md:flex overflow-scroll rounded-md bg-code\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[\"$\",\"$L16\",null,{\"lang\":\"asm\",\"lineNumbers\":false,\"code\":\"// fetch_add function\\nfetch_add:\\n        mov     eax, 1\\n.LBB0_1:\\n        lock            add     qword ptr [rdi], rax\\n        lea     rcx, [rax + 1]\\n        lock            add     qword ptr [rdi], rcx\\n        lea     rcx, [rax + 2]\\n        lock            add     qword ptr [rdi], rcx\\n        lea     rcx, [rax + 3]\\n        lock            add     qword ptr [rdi], rcx\\n        lea     rcx, [rax + 4]\\n        lock            add     qword ptr [rdi], rcx\\n        lea     rcx, [rax + 5]\\n        lock            add     qword ptr [rdi], rcx\\n        lea     rcx, [rax + 6]\\n        lock            add     qword ptr [rdi], rcx\\n        lea     rcx, [rax + 7]\\n        lock            add     qword ptr [rdi], rcx\\n        lea     rcx, [rax + 8]\\n        lock            add     qword ptr [rdi], rcx\\n        add     rax, 9\\n        cmp     rax, 10000000\\n        jne     .LBB0_1\\n        ret\"}]}]}],[\"$\",\"p\",null,{\"children\":[\"There is indeed some form of locking involved with the atomic \",[\"$\",\"mark\",null,{\"children\":\"fetch_add\"}],\". I'm guessing this is the reason behind the results, there isn't really much else in the function. I don't see it as a discouraging fact though, just because there is \",[\"$\",\"em\",null,{\"children\":\"some form\"}],\" of locking it doesn't mean that we're back to square one. This form of hardware-level locking is \",[\"$\",\"em\",null,{\"children\":\"not like\"}],\" the mutexes we're used to, There are two important ideas to mention:\"]}],[\"$\",\"ul\",null,{\"className\":\"my-2 text-textcolor list-disc\",\"children\":[[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":\"we are avoiding explicit locking acquisition and release in the code. I bet this saves us time.\"}],[\"$\",\"li\",null,{\"className\":\"ml-8\",\"children\":\"Progress is guaranteed in a well-designed lock-free multithreaded algorithm.\"}]]}],[\"$\",\"p\",null,{\"children\":[\"As I understand it, in lock-free multithreaded algorithms, one thread is guaranteed to make progress, so overall, our system doesn't reach a deadlocked state, and this is a significant victory. Of course we can still\",\" \",[\"$\",\"a\",null,{\"href\":\"https://lwn.net/Articles/847973/\",\"className\":\"underline\",\"rel\":\"nofollow\",\"target\":\"_blank\",\"children\":\"make mistakes\"}],\" \",\"in our program logic, leading to one thread to read the wrong/outaded value, so atomic operations alone aren't sufficient for logical soundness.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"In other words, since there is no mutual exclusion, shared memory is not \\\"locked\\\" so there is no \\\"holding and waiting\\\". We need to take that into account in the lock-free logic. A second thread can modify the shared memory while the first is still needing it, and due to it's logic, it's expecting to find the original value. We need to handle this problem, and that's where \",[\"$\",\"mark\",null,{\"children\":\"compare_exchange\"}],\" \",\"comes in handy. It compares the current shared value to the expected one, on success, the current variable is updated with the value. Together with a classic \",[\"$\",\"mark\",null,{\"children\":\"if\"}],\" statement it becomes a powerful tool.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"Also \",[\"$\",\"mark\",null,{\"children\":\"compare_exchange\"}],\" involves locking, although here we're packing more instructions in a single function:\"]}],[\"$\",\"div\",null,{\"className\":\"my-4 md:flex overflow-scroll rounded-md bg-code\",\"children\":[\"$\",\"div\",null,{\"className\":\"p-4\",\"children\":[\"$\",\"$L16\",null,{\"lang\":\"asm\",\"lineNumbers\":false,\"code\":\"// compare_exchange\\ncas:\\n        mov     edx, 1\\n        lea     rcx, [rsp - 16]\\n.LBB0_1:\\n        mov     rax, qword ptr [rdi]\\n        xor     esi, esi\\n        lock            cmpxchg qword ptr [rdi], rdx\\n        lea     r8, [rdx + 1]\\n        setne   sil\\n        mov     qword ptr [rsp - 16], rsi\\n        mov     qword ptr [rsp - 8], rax\\n        mov     rdx, r8\\n        cmp     r8, 10000000\\n        jne     .LBB0_1\\n        ret\"}]}]}],[\"$\",\"p\",null,{\"children\":[[\"$\",\"mark\",null,{\"children\":\"cmpxchg\"}],\" is the actual CAS operation but the other instructions are a necessary part of the whole compare exchange logic as well. I won't go into details here, there are good documents online that explain the logic. From our perspective, it seems reasonable that the CAS operation involves a performance degradation but in exchange we get the possibility to write logically sound, multithreaded and lock-free algorithms.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}]]}],[\"$\",\"h2\",null,{\"className\":\"mb-4\",\"children\":\" Conclusion \"}],[\"$\",\"p\",null,{\"children\":\"Lock-free algorithms are very interesting. I'm promising myself to write a part 2 where I show the logic of the FIFO queue I'm working on. For now, I hope somebody finds this useful or interesting.\"}]]}]\n"])</script><script>self.__next_f.push([1,"e:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n9:null\n"])</script><script>self.__next_f.push([1,"12:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Interface Blog\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"A blog by Gabriele Costanza about technology, ai, programming, data engineering and cloud technologies.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"application-name\",\"content\":\"interfaces_blog\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"interfaces_blog\"}],[\"$\",\"link\",\"4\",{\"rel\":\"canonical\",\"href\":\"https://gabrielecodes.github.io/interfaces_blog/\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:title\",\"content\":\"interfaces_blog\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:description\",\"content\":\"A blog by Gabriele Costanza about technology, ai, programming, data engineering and cloud technologies.\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:url\",\"content\":\"https://gabrielecodes.github.io/interfaces_blog/\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:site_name\",\"content\":\"interfaces_blog\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"11\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"12\",{\"name\":\"twitter:title\",\"content\":\"interfaces_blog\"}],[\"$\",\"meta\",\"13\",{\"name\":\"twitter:description\",\"content\":\"A blog by Gabriele Costanza about technology, ai, programming, data engineering and cloud technologies.\"}],[\"$\",\"link\",\"14\",{\"rel\":\"icon\",\"href\":\"/interfaces_blog/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]],\"error\":null,\"digest\":\"$undefined\"}\nc:{\"metadata\":\"$12:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>